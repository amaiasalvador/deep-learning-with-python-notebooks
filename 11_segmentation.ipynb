{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will see how to build a simple ConvNet for a toy semantic segmentation problem. We train the network from scratch and we will see the particularities of the problem. Finally, we will use a state of the art object detection network on some real-world images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A toy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deal with images with simple objects of different shapes and colors. Our goal is: given an image with objects of different shapes and colors, classify each pixel with a label corresponding the type of object it belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the dataset ourselves with these lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "palette = {(0,0,0):0, (0,0,255):1,(0,255,0):2,(255,0,0):3}\n",
    "def convert_from_color_segmentation(arr_3d, palette, image_height=32, image_width=32):\n",
    "\n",
    "    reshape_array = np.reshape(arr_3d, [image_height * image_width, 3])\n",
    "\n",
    "    #still too slow!!\n",
    "    arr_2d = np.fromiter([palette.get((x[0], x[1], x[2]), 0) for x in reshape_array],\n",
    "                         reshape_array.dtype)\n",
    "\n",
    "    return np.reshape(np.asarray(arr_2d), arr_3d.shape[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cairo\n",
    "num_imgs = 5000\n",
    "\n",
    "img_size = 32\n",
    "min_object_size = 4\n",
    "max_object_size = 16\n",
    "num_objects = 4\n",
    "\n",
    "shape_labels = ['rectangle', 'circle', 'triangle']\n",
    "num_shapes = len(shape_labels)\n",
    "\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)  # format: BGRA\n",
    "masks = np.zeros((num_imgs, img_size, img_size, 4), dtype=np.uint8)\n",
    "masks_decoded = []\n",
    "shapes = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "colors = np.zeros((num_imgs, num_objects), dtype=int)\n",
    "\n",
    "colors = [[0,0,1],[0,1,0],[1,0,0],[1,0,1],[1,1,0]]\n",
    "num_colors = len(colors)\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    \n",
    "    surface = cairo.ImageSurface.create_for_data(imgs[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
    "    surface_mask = cairo.ImageSurface.create_for_data(masks[i_img], cairo.FORMAT_ARGB32, img_size, img_size)\n",
    "    \n",
    "    cr = cairo.Context(surface)\n",
    "    cr_mask = cairo.Context(surface_mask)\n",
    "    # Fill background white.\n",
    "    cr.set_source_rgb(1, 1, 1)\n",
    "    cr.paint()\n",
    "    \n",
    "    cr_mask.set_source_rgb(0,0,0)\n",
    "    cr_mask.paint()\n",
    "    \n",
    "    # Draw random shapes.\n",
    "    for i_object in range(num_objects):\n",
    "        shape = np.random.randint(num_shapes)\n",
    "        shapes[i_img, i_object] = shape\n",
    "        if shape == 0:  # rectangle\n",
    "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "            x = np.random.randint(0, img_size - w)\n",
    "            y = np.random.randint(0, img_size - h)\n",
    "            cr.rectangle(x, y, w, h)\n",
    "            cr_mask.rectangle(x, y, w, h)\n",
    "            cr_mask.set_source_rgb(0,0,1)\n",
    "            cr_mask.fill()\n",
    "        elif shape == 1:  # circle   \n",
    "            r = 0.5 * np.random.randint(min_object_size, max_object_size)\n",
    "            x = np.random.randint(r, img_size - r)\n",
    "            y = np.random.randint(r, img_size - r)\n",
    "            cr.arc(x, y, r, 0, 2*np.pi)\n",
    "            cr_mask.arc(x, y, r, 0, 2*np.pi)\n",
    "            cr_mask.set_source_rgb(0,1,0)\n",
    "            cr_mask.fill()\n",
    "        elif shape == 2:  # triangle\n",
    "            w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "            x = np.random.randint(0, img_size - w)\n",
    "            y = np.random.randint(0, img_size - h)\n",
    "            cr.move_to(x, y)\n",
    "            cr.line_to(x+w, y)\n",
    "            cr.line_to(x+w, y+h)\n",
    "            cr.line_to(x, y)\n",
    "            cr.close_path()\n",
    "            \n",
    "            cr_mask.move_to(x, y)\n",
    "            cr_mask.line_to(x+w, y)\n",
    "            cr_mask.line_to(x+w, y+h)\n",
    "            cr_mask.line_to(x, y)\n",
    "            cr_mask.close_path()\n",
    "            \n",
    "            cr_mask.set_source_rgb(1,0,0)\n",
    "            cr_mask.fill()\n",
    "        \n",
    "        # TODO: Introduce some variation to the colors by adding a small random offset to the rgb values.\n",
    "        color = np.random.randint(num_colors)\n",
    "        r,g,b = colors[color]\n",
    "        max_offset = 0.3\n",
    "        r_offset, g_offset, b_offset = max_offset * 2. * (np.random.rand(3) - 0.5)\n",
    "        cr.set_source_rgb(r-max_offset+r_offset, g+g_offset, b+b_offset)\n",
    "        cr.fill()\n",
    "    masks_decoded.append(convert_from_color_segmentation(masks[i_img][:,:,0:3],palette))\n",
    "        \n",
    "imgs = imgs[..., 2::-1]\n",
    "masks_decoded = np.array(masks_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_decoded.shape, imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the samples we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks_decoded[2])\n",
    "plt.show()\n",
    "plt.imshow(imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "masks_decoded = masks_decoded.reshape(-1,1)\n",
    "masks_decoded_cat = to_categorical(masks_decoded,num_classes = len(shape_labels) + 1)\n",
    "masks_decoded_cat = masks_decoded_cat.reshape(num_imgs,img_size,img_size,len(shape_labels) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (imgs - np.mean(imgs)) / np.std(imgs)\n",
    "X.shape, np.mean(X), np.std(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_train = int(0.6 * num_imgs)\n",
    "i_val = int(0.7 * num_imgs)\n",
    "\n",
    "train_X = X[:i_train]\n",
    "val_X = X[i_train:i_val]\n",
    "test_X = X[i_val:]\n",
    "train_y = masks_decoded_cat[:i_train]\n",
    "val_y = masks_decoded_cat[i_train:i_val]\n",
    "test_y = masks_decoded_cat[i_val:]\n",
    "test_imgs = imgs[i_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple model composed of 4 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters=64,kernel_size=3, input_shape=(X.shape[1:]),activation='relu',padding='same'), \n",
    "        Conv2D(filters=64,kernel_size=3,activation='relu', padding='same'),\n",
    "        Conv2D(filters=32,kernel_size=3,activation='relu', padding='same'),\n",
    "        Conv2D(filters=num_shapes+1,kernel_size=3,activation='softmax',padding='same')\n",
    "    ])\n",
    "model.compile('adadelta', 'categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "history = model.fit(train_X,train_y,batch_size=512,epochs=n_epochs,validation_data=(val_X,val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangle:1, Circle:2, Square:3\n",
    "\n",
    "for i,pred in enumerate(preds[0:5]):\n",
    "    fig, (ax0, ax1,ax2) = plt.subplots(ncols=3,figsize=(30,10))\n",
    "    argmax_pred = np.argmax(pred,axis=-1)\n",
    "    cf0 = ax0.imshow(test_imgs[i])\n",
    "    fig.colorbar(cf0,ax=ax0)\n",
    "    cf1 = ax1.imshow(argmax_pred,vmin=0,vmax=3,cmap='magma')\n",
    "    fig.colorbar(cf1,ax=ax1)\n",
    "    cf2 = ax2.imshow(np.argmax(test_y[i],axis=-1),vmin=0,vmax=3,cmap='magma')\n",
    "    fig.colorbar(cf2,ax=ax2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Segmentation of Real-World Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://github.com/mzaradzki/neuralnets/blob/master/vgg_segmentation_keras/fcn16s_segmentation_keras2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
